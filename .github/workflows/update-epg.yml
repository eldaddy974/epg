name: Build Custom EPG from Your M3U (Google Drive)

on:
  workflow_dispatch:
  push:
    branches: [ main ]
    paths:
      - ".github/workflows/update-epg.yml"
      - "README.md"

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install lxml requests unidecode gdown

      - name: Download playlist from Google Drive (robust)
        env:
          FILE_ID: 1ycrzgwIoDsf_Rc11V3jj1D47mF33RTID
        run: |
          set -euo pipefail
          gdown --id "$FILE_ID" --output playlist.m3u
          echo "Playlist bytes: $(wc -c < playlist.m3u || true)"
          head -n 5 playlist.m3u || true

      - name: Write builder script
        run: |
          cat > build_epg.py <<'PY'
          import os, re, sys, io, gzip, traceback
          from lxml import etree
          import requests
          from unidecode import unidecode

          UA = ("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                "(KHTML, like Gecko) Chrome/124.0 Safari/537.36")

          # Mirrors + path templates. We'll try *.xml.gz first, then *.xml.
          MIRRORS = [
            "https://cdn.jsdelivr.net/gh/iptv-org/epg@master/guides/{name}",
            "https://raw.githubusercontent.com/iptv-org/epg/master/guides/{name}",
            "https://iptv-org.github.io/epg/guides/{name}",
          ]
          NAMES_FOR_CC = lambda cc: [f"{cc}.xml.gz", f"{cc}.xml"]
          NAMES_ALL     = ["all.xml.gz", "all.xml"]

          def http_get(url):
            try:
              r = requests.get(url, timeout=90, headers={"User-Agent": UA})
              return r.status_code, r.content
            except Exception as e:
              print(f"     ERR {url}: {e}")
              return 599, b""

          def fetch_one(name):
            for m in MIRRORS:
              url = m.format(name=name)
              code, body = http_get(url)
              if code == 200:
                # Decompress if gzipped (by content, not by extension)
                if body[:2] == b"\x1f\x8b":
                  body = gzip.GzipFile(fileobj=io.BytesIO(body)).read()
                print(f"     OK  {url}")
                return body
              else:
                print(f"     SKIP {code} {url}")
            return None

          def fetch_cc(cc):
            for nm in NAMES_FOR_CC(cc):
              data = fetch_one(nm)
              if data: return data
            return None

          def fetch_all():
            for nm in NAMES_ALL:
              data = fetch_one(nm)
              if data: return data
            return None

          def norm(s: str) -> str:
            if not s: return ""
            s = unidecode(s).strip().lower()
            s = re.sub(r"\s+", " ", s)
            return s

          try:
            if not os.path.exists("playlist.m3u") or os.path.getsize("playlist.m3u") == 0:
              print("FATAL: playlist.m3u missing or empty"); sys.exit(1)

            txt = open("playlist.m3u","r",encoding="utf-8",errors="ignore").read()

            tvg_ids  = set(m.group(1).strip() for m in re.finditer(r'tvg-id="([^"]+)"', txt))
            names    = set(m.group(1).strip() for m in re.finditer(r'tvg-name="([^"]+)"', txt))
            names   |= set(m.group(1).strip() for m in re.finditer(r"#EXTINF:[^\n]*?,\s*([^\r\n]+)", txt))
            names_n  = {norm(n) for n in names if n}
            tvg_ids  = {i for i in tvg_ids if i}

            print(f"Playlist: {len(tvg_ids)} unique tvg-ids; {len(names)} names")

            # Probe for countries mentioned; if none, try common ones.
            cc_list = ["fr","gb","us","ca","de","es","it","pt","nl","be","se","no","dk","fi","pl","ch","at","ie"]
            txt_low = txt.lower()
            maybe   = {cc for cc in cc_list if re.search(rf"\\b{cc}\\b", txt_low)}
            if not maybe: maybe = {"fr","gb","us"}
            print("Will try feeds:", sorted(maybe))

            root = etree.Element("tv")
            channels_seen = set()
            progs = 0
            any_ok = False

            # 1) Try per-country
            for cc in sorted(maybe):
              print(f"Fetch {cc}")
              data = fetch_cc(cc)
              if not data:
                continue
              any_ok = True
              try:
                doc = etree.fromstring(data)
              except Exception as e:
                print("  parse error", cc, e)
                continue

              for ch in doc.findall("channel"):
                cid = ch.get("id") or ""
                cname = (ch.findtext("display-name") or "").strip()
                if tvg_ids and cid not in tvg_ids:
                  if cname and norm(cname) not in names_n:
                    continue
                if cid not in channels_seen:
                  channels_seen.add(cid)
                  root.append(ch)

              for pr in doc.findall("programme"):
                cid = pr.get("channel") or ""
                if (not tvg_ids) or (cid in channels_seen):
                  root.append(pr); progs += 1

              print(f"  Tally: channels {len(channels_seen)}, programmes {progs}")

            # 2) If we still have nothing, fall back to ALL
            if not channels_seen:
              print("Per-country failed. Falling back to ALLâ€¦")
              data = fetch_all()
              if data:
                any_ok = True
                try:
                  doc = etree.fromstring(data)
                except Exception as e:
                  print("  parse error ALL", e)
                  doc = None
                if doc is not None:
                  for ch in doc.findall("channel"):
                    cid = ch.get("id") or ""
                    cname = (ch.findtext("display-name") or "").strip()
                    if tvg_ids and cid not in tvg_ids:
                      if cname and norm(cname) not in names_n:
                        continue
                    if cid not in channels_seen:
                      channels_seen.add(cid)
                      root.append(ch)
                  for pr in doc.findall("programme"):
                    cid = pr.get("channel") or ""
                    if (not tvg_ids) or (cid in channels_seen):
                      root.append(pr); progs += 1

            if not any_ok:
              print("ERROR: No EPG sources could be downloaded.")
            else:
              print(f"Done. channels written={len(channels_seen)}, programmes written={progs}")

            open("epg.xml","wb").write(
              etree.tostring(root, encoding="utf-8", xml_declaration=True)
            )

          except Exception:
            traceback.print_exc(); sys.exit(1)
          PY

      - name: Build epg.xml filtered to your channels
        run: |
          set -euo pipefail
          python build_epg.py

      - name: Commit epg.xml
        run: |
          if [ ! -s epg.xml ]; then
            echo "epg.xml missing or empty"; exit 1
          fi
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add epg.xml
          if git diff --cached --quiet; then
            echo "No changes to commit."
          else
            git commit -m "chore: update epg from Drive playlist"
            git push
          fi
